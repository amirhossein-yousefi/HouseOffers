{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "German_BERT_rent_prediction.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SF1Su28XHXyv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUSCFOz4LaSt",
    "outputId": "63d3a877-1757-4ced-ffcd-c17da2a639fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data=pd.read_csv('drive/MyDrive/immo_data_clean2.csv',lineterminator='\\n')\n",
    "handy_data=data.copy()"
   ],
   "metadata": {
    "id": "QQ1YIJVVLaVf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_rid_outl(df, list_num_var, percentile):\n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "    df: Dataframe\n",
    "    list_num_var: List of the variables (columns) with outliers that need to be deleted\n",
    "    percentile: float between 0 and 100: Percentage of the data that will be kept \n",
    "    \n",
    "    OUTPUT:\n",
    "    DataFrame with the defined amount of data. This means a DataFrame without outliers\n",
    "    \"\"\"\n",
    "    \n",
    "    perc_dict = {}\n",
    "    for col in list_num_var: # first, calculate all the percentiles before removing any\n",
    "        # row, otherwise you will remove more rows than necessary\n",
    "        value_perc = np.nanpercentile(df[col], percentile)\n",
    "        value_perc_dict = {col: value_perc}\n",
    "        perc_dict.update(value_perc_dict)\n",
    "        \n",
    "    for var in list_num_var:    \n",
    "        df = df.loc[(df[var] <= perc_dict[var]) ^ (df[var].isnull())] # include nan values\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "id": "v4ybvX7xR_Cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "handy_data.loc[handy_data.yearConstructed == \"NO_INFORMATION\", \"yearConstructed\"] = '0'\n",
    "handy_data['yearConstructed']=handy_data['yearConstructed'].astype(int)\n",
    "handy_data.loc[handy_data.yearConstructed == 0, \"yearConstructed\"] = None"
   ],
   "metadata": {
    "id": "M_NEOuPGR_Hr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "handy_data['yearConstructed'] = handy_data['yearConstructed'].fillna(handy_data['yearConstructed'].median())"
   ],
   "metadata": {
    "id": "jj3ur4yKR_KV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "handy_data.drop(columns=['totalRent',\n",
    "                 'serviceCharge',\n",
    "                 'heatingCosts'], inplace=True)\n",
    "\n",
    "# rename the response variable to rent\n",
    "handy_data.rename(columns={'rent_incl_hc': 'rent'}, inplace=True)\n",
    "\n",
    "# remove all rows where living space is 0\n",
    "handy_data = handy_data[handy_data['livingSpace'] != 0]\n",
    "\n",
    "# create a new variable for the rent/livingSpace (rent/m2)\n",
    "handy_data['rent_m2'] = handy_data['rent'] / handy_data['livingSpace']\n",
    "\n",
    "# get rid of outliers\n",
    "handy_data = get_rid_outl(handy_data, ['rent_m2'], 99.8)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyJOtbaZR_ND",
    "outputId": "50e7bf05-e8f1-4488-9a61-12e37e5db057",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "handy_data.typeOfFlat.replace(np.nan, 'NO_INFORMATION', inplace=True)\n",
    "handy_data.interiorQuality.replace(np.nan, 'NO_INFORMATION', inplace=True)"
   ],
   "metadata": {
    "id": "rcaWTyS1R_Pu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "handy_data_new=handy_data[[feat for feat in handy_data.columns.to_list() if feat not in ['Unnamed: 0']] ]"
   ],
   "metadata": {
    "id": "XUfk3GJ9Sfx8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y = handy_data_new['rent']\n",
    "X = handy_data_new[[i for i in handy_data_new.columns if i not in ['rent', 'rent_m2']]]\n",
    "train, test = train_test_split(pd.concat([X,y],axis=1), test_size=0.2,random_state=42)\n",
    "df_train,df_test=train.copy(),test.copy()\n",
    "df_train['split']='train'\n",
    "df_test['split']='test'\n",
    "print('{:,} training samples'.format(len(df_train)))\n",
    "print('{:,} test samples'.format(len(df_test)))\n",
    "\n",
    "# Confirm the columns match between the two.\n",
    "assert(set(df_train.columns) == set(df_test.columns))\n",
    "\n",
    "# Combine the two into a single dataframe for processing. We'll split them back\n",
    "# apart later, using the 'split' column we added.\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "# Use empty string to represent any empty cells.\n",
    "df.fillna(value='', inplace=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZw0IUb0Sf0U",
    "outputId": "9ae06081-3a87-43fd-a830-667d27f9ee98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "173,613 training samples\n",
      "43,404 test samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot a histogram of the rental prices.\n",
    "ax = sns.histplot(df['rent'], bins=30)\n",
    "\n",
    "t = ax.set_title('Histogram of Rental prices')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "g9xcG5SLSf2x",
    "outputId": "48745616-563d-45bd-d338-a30f387b7628",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfRElEQVR4nO3df5RdZX3v8feH/CICmgTG3GQyMUFSbfDWgGOIyFIKGgK3ruC9VEKrBKQEBXrFqy5AW0GRVrsUW24VjZKSWCVJo15SGxpThLIsEjJADIQfzRiImRBIJASI2GDC9/6xn4Ht4ZyZMztzfmU+r7X2mr2/+9l7P885k/nmefYvRQRmZmZFHNLoCpiZWetyEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwpxErO4kbZR0cqPr0UiS3i9pq6Q9ko5rdH36IikkHTNI+5qc2jxsMPZnjeckYoNK0uOS3lMSO0/ST3uXI+LYiLijn/1MSX+8hteoqo32ZeDSiDg8Iu4vXZna/uv0B3ebpOsG4w+vpJMl9RzofoqKiF+mNu9vVB1scDmJ2JDUBMnpDcDGfsq8NSIOB94NnA18uOa1qqEm+MytBpxErO7yvRVJMyV1SXpO0lOSrkvF7kw/d6f/jb9D0iGS/kLSFkk7JC2R9Lrcfs9N656W9Jclx7la0gpJ/yjpOeC8dOyfSdotabukv5c0Mre/kHSxpE2Snpd0jaQ3Sror1Xd5vnxJG8vWVdIoSXuAYcDPJf2iv88rIrqB/wBm5Pb/R5LWp7rfJekPSj7fT0raIOlZScskHSrpMOBWYGL6TPdImtjf59DPd3mHpL+WdE/6TG6RNC6t6+1NXiDpl8BPSnuYksZJ+gdJT0h6RtL/q7KNl6ce2vOSHpV0ajX1tRqICE+eBm0CHgfeUxI7D/hpuTLAz4APpfnDgVlpfgoQwPDcdh8GuoGjU9kfAN9J66YDe4CTgJFkw0W/zR3n6rR8Jtl/nkYDbwNmAcPT8R4GLssdL4BbgNcCxwJ7gdvS8V8HPATMr/A5VKxrbt/H9PE5vrweeDOwHfh4Wj4O2AGcQJaM5qfPdFTu870HmAiMS+36SFp3MtBTcqxqPoeydQXuALYBbwEOA74P/GPJd7gkrRtd+r0C/wIsA8YCI4B399dG4E3AVmBi7jhvbPTv/lCdGl4BTwfXlP6h7wF256YXqJxE7gQ+BxxVsp/f+WOTYrcBF+eW30SWGIYDnwVuzq17DfAiv5tE7uyn7pcBP8wtB/DO3PK9wOW55a8Af1thXxXrmtt3f0nkOeDXaf5mXkkSNwDXlJR/NPcH+HHgg7l1fwN8I82fTEkSqfJz6CuJfDG3PD197sNy3+HR5b5XYALwEjC2zH4rthE4hizBvAcY0ejf+aE+eTjLauHMiBjTOwEX91H2AuD3gEckrZP0R32UnQhsyS1vIftjND6t29q7IiJeAJ4u2X5rfkHS70n6kaQn0xDXXwFHlWzzVG7+N2WWDy9Q12odn/Z/Ntn/yA9L8TcAn0jDPLsl7QY60jF7PZmbf6GPelb7OfQl/7luIetRHFVhfV4HsCsinimzrmIbIxveu4zsPwY7JC2VNLHMPqwOnESsoSJiU0ScA7we+BKwIo3dl3u89BNkf1x6TQb2kf1h3w5M6l0haTRwZOnhSpZvAB4BpkXEa4FPAyremqrrWrXILCcb9vtsCm8Frs0n6oh4TUTcXM0uy8QO9HPoyM1PJutx/aqfY0LWjnGSxlRYV7GNEfG9iDiJ7DMOst8dawAnEWsoSR+U1BYRL5ENfUE2xLEz/Tw6V/xm4OOSpko6nOx/zMsiYh+wAnifpBPTSeGr6f8P4RFkQ0Z7JL0Z+OhgtaufuhbxReBCSf8N+BbwEUknKHOYpP8h6Ygq9vMUcGT+ggQO/HP4oKTpkl4DfB5YEVVcwhsR28lO9H9d0lhJIyS9K62u2EZJb5J0iqRRwH+R9QhfGmCdbZA4iVijzQE2piuW/g6YFxG/ScNR1wL/kYYzZgGLgO+QnUd5jOwPyJ8DRMTGNL+UrFeyh2zcfG8fx/4k8CfA82R/tJYNYrsq1rWIiHgg7etTEdEFXAj8PfAM2Qn886rczyNkCW5z+lwncuCfw3eAm8iG0A4F/vcAtv0QWc/lEbLv67JUz77aOIosqf4qHfP1wJUDrLMNEkX4pVR28En/+99NNkTzWKPrc7CSdAfZ1VjfbnRdrDHcE7GDhqT3SXpNOqfyZeABsiuVzKxGnETsYDKX7IT2E8A0sqExd7XNasjDWWZmVph7ImZmVtiQeyDaUUcdFVOmTGl0NczMWsq99977q4hoK40PuSQyZcoUurq6Gl0NM7OWImlLubiHs8zMrDAnETMzK8xJxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJ5GDTHvHZCT1O7V3TG50Vc3sIFCzx55IOpTsTWyj0nFWRMRVkm4C3g08m4qeFxHrJYnszXZnAC+k+H1pX/OBv0jlvxARi1P8bWRvVBsNrAI+NtQf/f1Ez1bO/uZd/ZZbdtGJdaiNmR3savnsrL3AKRGxR9II4KeSbk3rPhURK0rKn072DohpwAnADcAJksYBVwGdQAD3SloZEc+kMhcCa8mSyByydzabmVkd1Gw4KzJ70uKINPXVS5gLLEnb3Q2MkTQBOA1YExG7UuJYA8xJ614bEXen3scS4MxatcfMzF6tpudEJA2TtB7YQZYI1qZV10raIOmrkkalWDuwNbd5T4r1Fe8pEy9XjwWSuiR17dy584DbZWZmmZomkYjYHxEzgEnATElvAa4E3gy8HRgHXF7LOqR6LIyIzojobGt71ePwzcysoLpcnRURu4HbgTkRsT0NWe0F/gGYmYptAzpym01Ksb7ik8rEzcysTmqWRCS1SRqT5kcD7wUeSecySFdjnQk8mDZZCZyrzCzg2YjYDqwGZksaK2ksMBtYndY9J2lW2te5wC21ao+Zmb1aLa/OmgAsljSMLFktj4gfSfqJpDZAwHrgI6n8KrLLe7vJLvE9HyAidkm6BliXyn0+Inal+Yt55RLfW/GVWWZmdVWzJBIRG4DjysRPqVA+gEsqrFsELCoT7wLecmA1NTOzonzHupmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJD1SHD/fIqMztgtbxj3ZrZS/v88iozO2DuiZiZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRVWsyQi6VBJ90j6uaSNkj6X4lMlrZXULWmZpJEpPiotd6f1U3L7ujLFH5V0Wi4+J8W6JV1Rq7aYmVl5teyJ7AVOiYi3AjOAOZJmAV8CvhoRxwDPABek8hcAz6T4V1M5JE0H5gHHAnOAr0saJmkY8DXgdGA6cE4qa2ZmdVKzJBKZPWlxRJoCOAVYkeKLgTPT/Ny0TFp/qiSl+NKI2BsRjwHdwMw0dUfE5oh4EViaypqZWZ3U9JxI6jGsB3YAa4BfALsjYl8q0gO0p/l2YCtAWv8scGQ+XrJNpXi5eiyQ1CWpa+fOnYPRNDMzo8ZJJCL2R8QMYBJZz+HNtTxeH/VYGBGdEdHZ1tbWiCqYmR2U6nJ1VkTsBm4H3gGMkdT7MqxJwLY0vw3oAEjrXwc8nY+XbFMpbmZmdVLLq7PaJI1J86OB9wIPkyWTs1Kx+cAtaX5lWiat/0lERIrPS1dvTQWmAfcA64Bp6WqvkWQn31fWqj1mZvZqtXw97gRgcbqK6hBgeUT8SNJDwFJJXwDuB25M5W8EviOpG9hFlhSIiI2SlgMPAfuASyJiP4CkS4HVwDBgUURsrGF7zMysRM2SSERsAI4rE99Mdn6kNP5fwB9X2Ne1wLVl4quAVQdcWTMzK8R3rJuZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaF1SyJSOqQdLukhyRtlPSxFL9a0jZJ69N0Rm6bKyV1S3pU0mm5+JwU65Z0RS4+VdLaFF8maWSt2mNmZq9Wy57IPuATETEdmAVcIml6WvfViJiRplUAad084FhgDvB1ScMkDQO+BpwOTAfOye3nS2lfxwDPABfUsD1mZlaiZkkkIrZHxH1p/nngYaC9j03mAksjYm9EPAZ0AzPT1B0RmyPiRWApMFeSgFOAFWn7xcCZtWmNmZmVU5dzIpKmAMcBa1PoUkkbJC2SNDbF2oGtuc16UqxS/Ehgd0TsK4mXO/4CSV2Sunbu3DkILTIzM6hDEpF0OPB94LKIeA64AXgjMAPYDnyl1nWIiIUR0RkRnW1tbbU+nJnZkFHTJCJpBFkC+W5E/AAgIp6KiP0R8RLwLbLhKoBtQEdu80kpVin+NDBG0vCSuA2mQ4Yjqd+pvWNyo2tqZg0wvP8ixaRzFjcCD0fEdbn4hIjYnhbfDzyY5lcC35N0HTARmAbcAwiYJmkqWZKYB/xJRISk24GzyM6TzAduqVV7hqyX9nH2N+/qt9iyi06sQ2XMrNnULIkA7wQ+BDwgaX2KfZrs6qoZQACPAxcBRMRGScuBh8iu7LokIvYDSLoUWA0MAxZFxMa0v8uBpZK+ANxPlrTMzKxOapZEIuKnZL2IUqv62OZa4Noy8VXltouIzbwyHGZmZnXmO9bNzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRFpAe8fkqt5znr2R2Mysfmr5elwbJE/0bK3qPefgd52bWX1V1ROR9M5qYmZmNrRUO5z1f6uMmZnZENJnEpH0DkmfANok/Z/cdDUwrJ9tOyTdLukhSRslfSzFx0laI2lT+jk2xSXpekndkjZIOj63r/mp/CZJ83Pxt0l6IG1zvXxSwMysrvrriYwEDic7d3JEbnoOOKufbfcBn4iI6cAs4BJJ04ErgNsiYhpwW1oGOB2YlqYFwA2QJR3gKuAEYCZwVW/iSWUuzG03p/8mm5nZYOnzxHpE/Dvw75JuiogtA9lxRGwHtqf55yU9DLQDc4GTU7HFwB3A5Sm+JCICuFvSGEkTUtk1EbELQNIaYI6kO4DXRsTdKb4EOBO4dSD1NDOz4qq9OmuUpIXAlPw2EXFKNRtLmgIcB6wFxqcEA/AkMD7NtwNbc5v1pFhf8Z4y8XLHX0DWu2Hy5MnVVNnMzKpQbRL5J+AbwLeB/QM5gKTDge8Dl0XEc/nTFhERkmIg+ysiIhYCCwE6Oztrfjwzs6Gi2iSyLyJuGOjOJY0gSyDfjYgfpPBTkiZExPY0XLUjxbcBHbnNJ6XYNl4Z/uqN35Hik8qUNzOzOqn2Et9/lnSxpAnp6qpx6YR3RelKqRuBhyPiutyqlUDvFVbzgVty8XPTVVqzgGfTsNdqYLaksemE+mxgdVr3nKRZ6Vjn5vZlZmZ1UG1PpPeP/qdysQCO7mObdwIfAh6QtD7FPg18EVgu6QJgC/CBtG4VcAbQDbwAnA8QEbskXQOsS+U+33uSHbgYuAkYTXZC3SfVzczqqKokEhFTB7rjiPgpUOm+jVPLlA/gkgr7WgQsKhPvAt4y0LqZmdngqCqJSDq3XDwilgxudczMrJVUO5z19tz8oWQ9ifsAJxHLHDK8qqcIT5zUwbatv6xDhcysHqodzvrz/LKkMcDSmtTIWtNL+6p60rCfMmx2cCn6PpFfAwM+T2JmZgeXas+J/DPZ1ViQPXjx94HltaqUmZm1hmrPiXw5N78P2BIRPZUKm5nZ0FDVcFZ6EOMjZE/wHQu8WMtKmZlZa6j2zYYfAO4B/pjs5sC1kvp7FLyZmR3kqh3O+gzw9ojYASCpDfg3YEWtKmZmZs2v2quzDulNIMnTA9jWzMwOUtX2RP5V0mrg5rR8NtmzrszMbAjrM4lIOobsJVKfkvQ/gZPSqp8B36115czMrLn11xP5W+BKgPQ+kB8ASPrvad37alo7MzNrav2d1xgfEQ+UBlNsSk1qZGZmLaO/JDKmj3WjB7MiZmbWevpLIl2SLiwNSvoz4N7aVMnMzFpFf+dELgN+KOlPeSVpdAIjgffXsmJmZtb8+kwiEfEUcKKkP+SVNwj+S0T8pOY1MzOzplft+0RuB26vcV3MzKzF+K5zMzMrrGZJRNIiSTskPZiLXS1pm6T1aTojt+5KSd2SHpV0Wi4+J8W6JV2Ri0+VtDbFl0kaWau2mJlZebXsidwEzCkT/2pEzEjTKgBJ04F5wLFpm69LGiZpGPA14HRgOnBOKgvwpbSvY4BngAtq2BYzMyujZkkkIu4EdlVZfC6wNCL2RsRjQDcwM03dEbE5Il4ke6/7XEkCTuGVpwgvBs4c1AaYmVm/GnFO5FJJG9Jw19gUawe25sr0pFil+JHA7ojYVxIvS9ICSV2Sunbu3DlY7TAzG/LqnURuAN4IzAC2A1+px0EjYmFEdEZEZ1tbWz0OaZUcMhxJ/U7tHZMbXVMzq0K1j4IfFOm+EwAkfQv4UVrcBnTkik5KMSrEnwbGSBqeeiP58tbMXtrH2d+8q99iyy46sQ6VMbMDVdeeiKQJucX3A71Xbq0E5kkaJWkqMI3sdbzrgGnpSqyRZCffV0ZEkN230vuK3vnALfVog5mZvaJmPRFJNwMnA0dJ6gGuAk6WNAMI4HHgIoCI2ChpOfAQsA+4JCL2p/1cCqwGhgGLImJjOsTlwFJJXwDuB26sVVvMzKy8miWRiDinTLjiH/qIuBa4tkx8FWXeohgRm8mu3jIzswbxHetmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiDUn39lu1hLqese6WdV8Z7tZS3BPxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCqtZEpG0SNIOSQ/mYuMkrZG0Kf0cm+KSdL2kbkkbJB2f22Z+Kr9J0vxc/G2SHkjbXC9JtWqLmZmVV8ueyE3AnJLYFcBtETENuC0tA5wOTEvTAuAGyJIOcBVwAjATuKo38aQyF+a2Kz2WmZnVWM2SSETcCewqCc8FFqf5xcCZufiSyNwNjJE0ATgNWBMRuyLiGWANMCete21E3B0RASzJ7cvMzOqk3udExkfE9jT/JDA+zbcDW3PlelKsr3hPmXhZkhZI6pLUtXPnzgNrgZmZvaxhJ9ZTDyLqdKyFEdEZEZ1tbW31OKSZ2ZBQ7yTyVBqKIv3ckeLbgI5cuUkp1ld8Upm4mZnVUb2TyEqg9wqr+cAtufi56SqtWcCzadhrNTBb0th0Qn02sDqte07SrHRV1rm5fdlQcshwJFU1tXdMbnRtzQ46w2u1Y0k3AycDR0nqIbvK6ovAckkXAFuAD6Tiq4AzgG7gBeB8gIjYJekaYF0q9/mI6D1ZfzHZFWCjgVvTZEPNS/s4+5t3VVV02UUn1rgyZkNPzZJIRJxTYdWpZcoGcEmF/SwCFpWJdwFvOZA6mpnZgfEd62ZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiQ0eVNyb6pkSz6tXsPhGzplPljYm+KdGseu6JmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4hZKd9PYlY13ydiVsr3k5hVzT0RMzMrzEnEzMwKcxJpoPaOyVWNvZuZNSufE2mgJ3q2euzdzFpaQ3oikh6X9ICk9ZK6UmycpDWSNqWfY1Nckq6X1C1pg6Tjc/uZn8pvkjS/EW0xMxvKGjmc9YcRMSMiOtPyFcBtETENuC0tA5wOTEvTAuAGyJIOcBVwAjATuKo38ZjVhS8FNmuq4ay5wMlpfjFwB3B5ii+JiADuljRG0oRUdk1E7AKQtAaYA9xc32rbkOVLgc0a1hMJ4MeS7pW0IMXGR8T2NP8kMD7NtwNbc9v2pFil+KtIWiCpS1LXzp07B6sNZmZDXqN6IidFxDZJrwfWSHokvzIiQlIM1sEiYiGwEKCzs3PQ9mtmNtQ1pCcSEdvSzx3AD8nOaTyVhqlIP3ek4tuAjtzmk1KsUtzMzOqk7klE0mGSjuidB2YDDwIrgd4rrOYDt6T5lcC56SqtWcCzadhrNTBb0th0Qn12ipk1F5+At4NYI4azxgM/TDfRDQe+FxH/KmkdsFzSBcAW4AOp/CrgDKAbeAE4HyAidkm6BliXyn2+9yS7WVPxCXg7iNU9iUTEZuCtZeJPA6eWiQdwSYV9LQIWDXYdzcysOn7siZmZFeYkYmZmhTmJmDULn4C3FtRMd6ybDW0+AW8tyD0RMzMrzEnErNV42MuaiIezzFqNh72sibgnYmZmhTmJmJlZYU4iZmZWmJOI2cGqyhPwPglvB8In1s0OVlWegAefhLfi3BMxM182bIW5J2JmvmzYCnNPxMzMCnMSMbPqedjLSng4y8yq52EvK+GeiJkNPvdYhgz3RMxs8FXbY/nou5DUb7mJkzrYtvWXg1EzG2ROImbWOE42La/lk4ikOcDfAcOAb0fEFxtcJTMbbE42Taulk4ikYcDXgPcCPcA6SSsj4qFG1qu9YzJP9GxtZBXMhqZBTjYAw0aMYv9v9w5auYMtgbV0EgFmAt0RsRlA0lJgLlCTJDKQ5OArWMya2AAfCVPtv+fBTGCtkpQUEQ07+IGSdBYwJyL+LC1/CDghIi4tKbcAWJAW3wQ8WvCQRwG/Krhts3FbmpPb0pzcFnhDRLSVBlu9J1KViFgILDzQ/UjqiojOQahSw7ktzcltaU5uS2Wtfp/INqAjtzwpxczMrA5aPYmsA6ZJmippJDAPWNngOpmZDRktPZwVEfskXQqsJrvEd1FEbKzhIQ94SKyJuC3NyW1pTm5LBS19Yt3MzBqr1YezzMysgZxEzMysMCeRKkiaI+lRSd2Srmh0faoh6XFJD0haL6krxcZJWiNpU/o5NsUl6frUvg2Sjm9s7UHSIkk7JD2Yiw24/pLmp/KbJM1vorZcLWlb+n7WSzojt+7K1JZHJZ2Wizf091BSh6TbJT0kaaOkj6V4y30vfbSl5b6XVIdDJd0j6eepPZ9L8amS1qa6LUsXICFpVFruTuun5PZVtp0VRYSnPiayE/a/AI4GRgI/B6Y3ul5V1Ptx4KiS2N8AV6T5K4AvpfkzgFsBAbOAtU1Q/3cBxwMPFq0/MA7YnH6OTfNjm6QtVwOfLFN2evodGwVMTb97w5rh9xCYAByf5o8A/jPVt+W+lz7a0nLfS6qfgMPT/AhgbfrMlwPzUvwbwEfT/MXAN9L8PGBZX+3s69juifTv5UerRMSLQO+jVVrRXGBxml8MnJmLL4nM3cAYSRMaUcFeEXEnsKskPND6nwasiYhdEfEMsAaYU/va/64KbalkLrA0IvZGxGNAN9nvYMN/DyNie0Tcl+afBx4G2mnB76WPtlTStN8LQPqM96TFEWkK4BRgRYqXfje939kK4FRJonI7K3IS6V87kH9gVg99/7I1iwB+LOleZY99ARgfEdvT/JPA+DTfKm0caP2bvV2XpmGeRb1DQLRIW9Lwx3Fk/+Nt6e+lpC3Qot+LpGGS1gM7yBLzL4DdEbGvTN1ernda/yxwJAXa4yRy8DopIo4HTgcukfSu/MrI+q4te313q9cfuAF4IzAD2A58pbHVqZ6kw4HvA5dFxHP5da32vZRpS8t+LxGxPyJmkD25Yybw5noc10mkfy35aJWI2JZ+7gB+SPZL9VTvMFX6uSMVb5U2DrT+TduuiHgq/aN/CfgWrwwZNHVbJI0g+6P73Yj4QQq35PdSri2t+r3kRcRu4HbgHWRDiL03lefr9nK90/rXAU9ToD1OIv1ruUerSDpM0hG988Bs4EGyevdeCTMfuCXNrwTOTVfTzAKezQ1PNJOB1n81MFvS2DQsMTvFGq7knNP7yb4fyNoyL109MxWYBtxDE/wepjHzG4GHI+K63KqW+14qtaUVvxcASW2SxqT50WTvWHqYLJmclYqVfje939lZwE9SL7JSOyur91UErTiRXWXyn2RjjJ9pdH2qqO/RZFdY/BzY2FtnsjHP24BNwL8B41JcZC/3+gXwANDZBG24mWw44bdk47IXFKk/8GGyk4PdwPlN1JbvpLpuSP9wJ+TKfya15VHg9Gb5PQROIhuq2gCsT9MZrfi99NGWlvteUh3+ALg/1ftB4LMpfjRZEugG/gkYleKHpuXutP7o/tpZafJjT8zMrDAPZ5mZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZi1A0nmSJja6HmalnETM6izdfDfQf3vnAU4i1nScRMzqQNKU9H6GJWQ3g/2lpHXpQX+fy5V5WNK30jshfixptKSzgE7gu+kdF6Mb2RazPCcRs/qZBnwd+DjZk1Fnkj3o7225B2ROA74WEccCu4H/FRErgC7gTyNiRkT8pv5VNyvPScSsfrZE9l6N2Wm6H7iP7Gmr01KZxyJifZq/F5hS70qaDcTw/ouY2SD5dfop4K8j4pv5lem9Fntzof2Ah66sqbknYlZ/q4EPp3dZIKld0uv72eZ5ste4mjUV90TM6iwifizp94GfZU8kZw/wQbKeRyU3Ad+Q9BvgHT4vYs3CT/E1M7PCPJxlZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVtj/ByQKf+IBADSkAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lG70bMD4Sf5A",
    "outputId": "18b9f7ff-1e61-42b5-cbc8-290a78198aea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 217017 entries, 192241 to 55688\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   regionLevel1           217017 non-null  object \n",
      " 1   heatingType            217017 non-null  object \n",
      " 2   newlyConst             217017 non-null  bool   \n",
      " 3   balcony                217017 non-null  bool   \n",
      " 4   yearConstructed        217017 non-null  float64\n",
      " 5   noParkSpaces           217017 non-null  float64\n",
      " 6   kitchen                217017 non-null  bool   \n",
      " 7   cellar                 217017 non-null  bool   \n",
      " 8   livingSpace            217017 non-null  float64\n",
      " 9   condition              217017 non-null  object \n",
      " 10  interiorQuality        217017 non-null  object \n",
      " 11  petsAllowed            217017 non-null  object \n",
      " 12  lift                   217017 non-null  bool   \n",
      " 13  typeOfFlat             217017 non-null  object \n",
      " 14  postcode               217017 non-null  int64  \n",
      " 15  noRooms                217017 non-null  float64\n",
      " 16  floor                  217017 non-null  object \n",
      " 17  numberOfFloors         217017 non-null  object \n",
      " 18  garden                 217017 non-null  bool   \n",
      " 19  regionLevel2           217017 non-null  object \n",
      " 20  regionLevel3           217017 non-null  object \n",
      " 21  description            217017 non-null  object \n",
      " 22  facilities             217017 non-null  object \n",
      " 23  energyEfficiencyClass  217017 non-null  object \n",
      " 24  lastRefurbish          217017 non-null  object \n",
      " 25  rent                   217017 non-null  float64\n",
      " 26  split                  217017 non-null  object \n",
      "dtypes: bool(6), float64(5), int64(1), object(15)\n",
      "memory usage: 37.7+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "col_info = {}\n",
    "\n",
    "# Specify our text features.\n",
    "col_info['text_cols'] = [\n",
    "   # categorical features\n",
    "  'regionLevel1',\n",
    " 'heatingType',\n",
    " 'condition',\n",
    " 'interiorQuality',\n",
    " 'petsAllowed',\n",
    " 'typeOfFlat',\n",
    " 'floor',\n",
    " 'numberOfFloors',\n",
    " 'regionLevel2',\n",
    " 'regionLevel3',\n",
    " 'energyEfficiencyClass',\n",
    " 'lastRefurbish',\n",
    "    # Text Features.\n",
    "  'description',\n",
    "  'facilities'  \n",
    "]\n",
    "\n",
    "# Specify our numerical features.\n",
    "col_info['num_cols'] = [ \n",
    "  'yearConstructed',\n",
    "  'noParkSpaces',\n",
    "   'livingSpace',\n",
    "    'noRooms',\n",
    "    'postcode'\n",
    "]\n",
    "\n",
    "# Specify our categorical features--all of these are binary. \n",
    "col_info['cat_cols'] = [\n",
    " 'newlyConst',\n",
    " 'balcony',\n",
    " 'kitchen', \n",
    " 'cellar',\n",
    "  'lift', \n",
    "  'garden']\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "eKQoQ9iaUnRl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(col_info['text_cols'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtUAxYHme1vQ",
    "outputId": "15b711ac-fb09-4a69-cac1-717b254ec25f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('There are:')\n",
    "print('  {:,}  numerical features'.format(len(col_info['num_cols'])))\n",
    "print('  {:,}  categorical features'.format(len(col_info['cat_cols'])))\n",
    "print('  {:,}  text features'.format(len(col_info['text_cols'])))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_dn-cDnXnrH",
    "outputId": "ee246bb8-aa6d-465c-f268-402748c56012",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are:\n",
      "  5  numerical features\n",
      "  6  categorical features\n",
      "  14  text features\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Select just the columns we're using.\n",
    "data_df = df[col_info['text_cols'] +  \n",
    "             col_info['num_cols'] +\n",
    "             col_info['cat_cols'] + \n",
    "             ['rent', 'split']] # 'rent' is our label.\n",
    "              \n",
    "\n",
    "data_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "xTPNcHDXXuqw",
    "outputId": "37754be7-8d84-498e-9f0b-a014c0b84b2b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             regionLevel1                     heatingType  \\\n",
       "192241            Sachsen                 central_heating   \n",
       "131248            Sachsen                 central_heating   \n",
       "64389             Sachsen                                   \n",
       "155488  Baden_Württemberg  self_contained_central_heating   \n",
       "87135              Hessen                 central_heating   \n",
       "\n",
       "                                 condition interiorQuality petsAllowed  \\\n",
       "192241                           well_kept          normal  negotiable   \n",
       "131248                         refurbished          normal               \n",
       "64389                                       NO_INFORMATION               \n",
       "155488  first_time_use_after_refurbishment          normal          no   \n",
       "87135                            well_kept          normal  negotiable   \n",
       "\n",
       "            typeOfFlat floor  numberOfFloors  \\\n",
       "192241       apartment   1.0             2.0   \n",
       "131248     roof_storey   3.0  NO_INFORMATION   \n",
       "64389   NO_INFORMATION   1.0  NO_INFORMATION   \n",
       "155488       apartment   1.0             3.0   \n",
       "87135        apartment   1.0             2.0   \n",
       "\n",
       "                                  regionLevel2 regionLevel3  ... noRooms  \\\n",
       "192241  Sächsische_Schweiz_Osterzgebirge_Kreis      Freital  ...     2.0   \n",
       "131248                           Bautzen_Kreis    Bernsdorf  ...     4.0   \n",
       "64389                            Bautzen_Kreis    Hochkirch  ...     2.0   \n",
       "155488                               Stuttgart       Büsnau  ...     3.0   \n",
       "87135                             Gießen_Kreis     Langgöns  ...     3.0   \n",
       "\n",
       "       postcode newlyConst balcony  kitchen  cellar   lift  garden   rent  \\\n",
       "192241     1705      False   False     True    True  False    True  410.0   \n",
       "131248     2994      False   False    False    True  False   False  762.0   \n",
       "64389      2627      False   False    False   False  False   False  318.5   \n",
       "155488    70569      False    True    False    True  False   False  930.0   \n",
       "87135     35428      False    True    False    True  False   False  850.0   \n",
       "\n",
       "        split  \n",
       "192241  train  \n",
       "131248  train  \n",
       "64389   train  \n",
       "155488  train  \n",
       "87135   train  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7b774c00-6040-4c12-aada-16d34c86d591\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regionLevel1</th>\n",
       "      <th>heatingType</th>\n",
       "      <th>condition</th>\n",
       "      <th>interiorQuality</th>\n",
       "      <th>petsAllowed</th>\n",
       "      <th>typeOfFlat</th>\n",
       "      <th>floor</th>\n",
       "      <th>numberOfFloors</th>\n",
       "      <th>regionLevel2</th>\n",
       "      <th>regionLevel3</th>\n",
       "      <th>...</th>\n",
       "      <th>noRooms</th>\n",
       "      <th>postcode</th>\n",
       "      <th>newlyConst</th>\n",
       "      <th>balcony</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>cellar</th>\n",
       "      <th>lift</th>\n",
       "      <th>garden</th>\n",
       "      <th>rent</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>Sachsen</td>\n",
       "      <td>central_heating</td>\n",
       "      <td>well_kept</td>\n",
       "      <td>normal</td>\n",
       "      <td>negotiable</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sächsische_Schweiz_Osterzgebirge_Kreis</td>\n",
       "      <td>Freital</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1705</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>410.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131248</th>\n",
       "      <td>Sachsen</td>\n",
       "      <td>central_heating</td>\n",
       "      <td>refurbished</td>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td>roof_storey</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO_INFORMATION</td>\n",
       "      <td>Bautzen_Kreis</td>\n",
       "      <td>Bernsdorf</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2994</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>762.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>Sachsen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NO_INFORMATION</td>\n",
       "      <td></td>\n",
       "      <td>NO_INFORMATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_INFORMATION</td>\n",
       "      <td>Bautzen_Kreis</td>\n",
       "      <td>Hochkirch</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2627</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>318.5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>Baden_Württemberg</td>\n",
       "      <td>self_contained_central_heating</td>\n",
       "      <td>first_time_use_after_refurbishment</td>\n",
       "      <td>normal</td>\n",
       "      <td>no</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Büsnau</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70569</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>930.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87135</th>\n",
       "      <td>Hessen</td>\n",
       "      <td>central_heating</td>\n",
       "      <td>well_kept</td>\n",
       "      <td>normal</td>\n",
       "      <td>negotiable</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Gießen_Kreis</td>\n",
       "      <td>Langgöns</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35428</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>850.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b774c00-6040-4c12-aada-16d34c86d591')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7b774c00-6040-4c12-aada-16d34c86d591 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7b774c00-6040-4c12-aada-16d34c86d591');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## S2. Prepare Numerical & Categorical Features\n"
   ],
   "metadata": {
    "id": "XRMXu1YuY9RI",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A couple pre-processing steps need to be performed:\n",
    "\n",
    "1. Our binary features are currently represented as 't' or 'f', but we'll need to change this to 1 and 0.\n",
    "2. We'll normalize each numerical feature.\n",
    "\n"
   ],
   "metadata": {
    "id": "OeOQG2UmZAPk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Binary Features"
   ],
   "metadata": {
    "id": "JS61VfR-ZD8s",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace the 't' and 'f' values with 1 and 0. \n",
    " "
   ],
   "metadata": {
    "id": "1ziSa6eqZFyq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Disable those pesky \"SettingWithCopyWarning\" messages.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "print('Converting categorical features to integers...')\n",
    "\n",
    "# For each of the categorical features...\n",
    "for col_name in col_info['cat_cols']:\n",
    "\n",
    "    # Get the number of unique values for this category.\n",
    "    num_unique = len(data_df[col_name].unique())\n",
    "    \n",
    "    # If there are more than two, warn about it.\n",
    "    if num_unique > 2:\n",
    "        print('Note! Column \"{:}\" has {:,} possible values.'.format(col_name, num_unique))\n",
    "\n",
    "    # First, change the type of the specified columns to \"category\". This will \n",
    "    # assign a \"code\" to each unique category value.\n",
    "    data_df[col_name] = data_df[col_name].astype('category')\n",
    "\n",
    "    # Second, replace the strings with their code values.\n",
    "    data_df[col_name] = data_df[col_name].cat.codes.astype('float')\n",
    "\n",
    "print('DONE.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTVduTDXZDQT",
    "outputId": "6ced7541-1931-46ff-83ca-d3158d05b75a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting categorical features to integers...\n",
      "DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the category columns after the transformation.\n",
    "data_df[col_info['cat_cols']].head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "99bdwASdVUAY",
    "outputId": "32760224-7c67-41af-f97a-a20da8b4b34d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        newlyConst  balcony  kitchen  cellar  lift  garden\n",
       "192241         0.0      0.0      1.0     1.0   0.0     1.0\n",
       "131248         0.0      0.0      0.0     1.0   0.0     0.0\n",
       "64389          0.0      0.0      0.0     0.0   0.0     0.0\n",
       "155488         0.0      1.0      0.0     1.0   0.0     0.0\n",
       "87135          0.0      1.0      0.0     1.0   0.0     0.0"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-63e835a3-1cc9-4da4-87b4-a069edcc6ce9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newlyConst</th>\n",
       "      <th>balcony</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>cellar</th>\n",
       "      <th>lift</th>\n",
       "      <th>garden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63e835a3-1cc9-4da4-87b4-a069edcc6ce9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-63e835a3-1cc9-4da4-87b4-a069edcc6ce9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-63e835a3-1cc9-4da4-87b4-a069edcc6ce9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Normalize Feature Distributions"
   ],
   "metadata": {
    "id": "MhbilLhbZpsa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalization can help the MLP out if we shift and re-scale the ranges of each feature so they all have similar distributions, so we'll do normalization here.\n",
    "\n",
    "First, let's display the numerical features pre-transformation."
   ],
   "metadata": {
    "id": "3Y1OnqlaZriD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the numerical features prior to our transformation.\n",
    "data_df[col_info['num_cols']].head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "x1ipIC3eY5BX",
    "outputId": "d1dba3f5-e794-4f1d-c581-47aa8209df10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        yearConstructed  noParkSpaces  livingSpace  noRooms  postcode\n",
       "192241           1900.0           0.0        50.00      2.0      1705\n",
       "131248           1912.0           1.0        98.87      4.0      2994\n",
       "64389            1968.0           0.0        49.00      2.0      2627\n",
       "155488           1969.0           0.0        68.00      3.0     70569\n",
       "87135            1992.0           1.0        95.00      3.0     35428"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d5a81983-422f-4ece-a792-b6f3d00bd6c6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearConstructed</th>\n",
       "      <th>noParkSpaces</th>\n",
       "      <th>livingSpace</th>\n",
       "      <th>noRooms</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131248</th>\n",
       "      <td>1912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>1968.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>1969.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87135</th>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5a81983-422f-4ece-a792-b6f3d00bd6c6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d5a81983-422f-4ece-a792-b6f3d00bd6c6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d5a81983-422f-4ece-a792-b6f3d00bd6c6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Disable those pesky \"SettingWithCopyWarning\" messages.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# For each of the numerical featuress...\n",
    "for col_name in col_info['num_cols']:\n",
    "    \n",
    "    # Select the column.\n",
    "    num_df = data_df[col_name]\n",
    "\n",
    "    # Replace any empty cells with 0.\n",
    "    num_df.replace('', 0, inplace=True)\n",
    "\n",
    "    # The column values are a 1D array, but the transformation function requires\n",
    "    # it to be a 2D array. Reshape it into a column vector. \n",
    "    col_values = num_df.values.reshape(-1, 1)\n",
    "\n",
    "    # Create a quantile transformer that transforms the feature\n",
    "    # to have a normal distribution.\n",
    "    numerical_transformer = QuantileTransformer(output_distribution='normal')\n",
    "    \n",
    "    # Apply the transformation.\n",
    "    col_values_norm = numerical_transformer.fit_transform(col_values)\n",
    "\n",
    "    # Replace the values with the normalized ones.\n",
    "    data_df[col_name] = col_values_norm\n"
   ],
   "metadata": {
    "id": "DUS7mT6nY5D4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the numerical features after transformation.\n",
    "data_df[col_info['num_cols']].head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rGIlyk5JY5GL",
    "outputId": "793fd060-29cd-4ed8-eb35-fc42d3ac429d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        yearConstructed  noParkSpaces  livingSpace   noRooms  postcode\n",
       "192241        -1.649237     -5.199338    -0.844485 -0.552537 -1.773922\n",
       "131248        -1.171890      0.931971     1.061725  1.453280 -1.537691\n",
       "64389         -0.384375     -5.199338    -0.905189 -0.552537 -1.634517\n",
       "155488        -0.360172     -5.199338     0.060256  0.447305  1.088776\n",
       "87135          0.686350      0.931971     0.971436  0.447305 -0.023496"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7e47450e-84a8-43a4-9d15-69f141063230\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearConstructed</th>\n",
       "      <th>noParkSpaces</th>\n",
       "      <th>livingSpace</th>\n",
       "      <th>noRooms</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>-1.649237</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.844485</td>\n",
       "      <td>-0.552537</td>\n",
       "      <td>-1.773922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131248</th>\n",
       "      <td>-1.171890</td>\n",
       "      <td>0.931971</td>\n",
       "      <td>1.061725</td>\n",
       "      <td>1.453280</td>\n",
       "      <td>-1.537691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>-0.384375</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.905189</td>\n",
       "      <td>-0.552537</td>\n",
       "      <td>-1.634517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>-0.360172</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.447305</td>\n",
       "      <td>1.088776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87135</th>\n",
       "      <td>0.686350</td>\n",
       "      <td>0.931971</td>\n",
       "      <td>0.971436</td>\n",
       "      <td>0.447305</td>\n",
       "      <td>-0.023496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e47450e-84a8-43a4-9d15-69f141063230')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7e47450e-84a8-43a4-9d15-69f141063230 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7e47450e-84a8-43a4-9d15-69f141063230');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Combine Text"
   ],
   "metadata": {
    "id": "Xh-K62ZkaEHt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loop through the dataset and concatenate all of the text features together.\n"
   ],
   "metadata": {
    "id": "dODuMjquaHEj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text_combined = []\n",
    "\n",
    "print('Combining all text features...')\n",
    "\n",
    "# For each sample...\n",
    "for (i, row) in data_df.iterrows():\n",
    "\n",
    "    combined = ''\n",
    "\n",
    "    # For each of the text columns...\n",
    "    for text_col in col_info['text_cols']:\n",
    "        \n",
    "        # Append the feature to the combined text, with a 'SEP' token in between.\n",
    "        combined += (str(row[text_col]) + ' [SEP] ')\n",
    "\n",
    "    text_combined.append(combined)\n",
    "\n",
    "# Sanity check that the resulting list is the same length as the data frame.\n",
    "assert(len(text_combined) == len(data_df))\n",
    "\n",
    "print('  DONE.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5OwumwsaFfr",
    "outputId": "a56090e1-f407-4a05-a1d5-f3db410bc9ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combining all text features...\n",
      "  DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove the original text feature columns.\n",
    "data_df = data_df.drop(columns = col_info['text_cols'])\n",
    "\n",
    "# Add the combined text as the first column.\n",
    "data_df.insert(0, 'text', text_combined)\n",
    "\n",
    "data_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "UQze7WO2Y5If",
    "outputId": "360026a5-ca77-4910-c231-67de8acd285c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     text  yearConstructed  \\\n",
       "192241  Sachsen [SEP] central_heating [SEP] well_kept ...        -1.649237   \n",
       "131248  Sachsen [SEP] central_heating [SEP] refurbishe...        -1.171890   \n",
       "64389   Sachsen [SEP]  [SEP]  [SEP] NO_INFORMATION [SE...        -0.384375   \n",
       "155488  Baden_Württemberg [SEP] self_contained_central...        -0.360172   \n",
       "87135   Hessen [SEP] central_heating [SEP] well_kept [...         0.686350   \n",
       "\n",
       "        noParkSpaces  livingSpace   noRooms  postcode  newlyConst  balcony  \\\n",
       "192241     -5.199338    -0.844485 -0.552537 -1.773922         0.0      0.0   \n",
       "131248      0.931971     1.061725  1.453280 -1.537691         0.0      0.0   \n",
       "64389      -5.199338    -0.905189 -0.552537 -1.634517         0.0      0.0   \n",
       "155488     -5.199338     0.060256  0.447305  1.088776         0.0      1.0   \n",
       "87135       0.931971     0.971436  0.447305 -0.023496         0.0      1.0   \n",
       "\n",
       "        kitchen  cellar  lift  garden   rent  split  \n",
       "192241      1.0     1.0   0.0     1.0  410.0  train  \n",
       "131248      0.0     1.0   0.0     0.0  762.0  train  \n",
       "64389       0.0     0.0   0.0     0.0  318.5  train  \n",
       "155488      0.0     1.0   0.0     0.0  930.0  train  \n",
       "87135       0.0     1.0   0.0     0.0  850.0  train  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-dcdfab44-a17e-44fc-a7a8-da779e424235\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>yearConstructed</th>\n",
       "      <th>noParkSpaces</th>\n",
       "      <th>livingSpace</th>\n",
       "      <th>noRooms</th>\n",
       "      <th>postcode</th>\n",
       "      <th>newlyConst</th>\n",
       "      <th>balcony</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>cellar</th>\n",
       "      <th>lift</th>\n",
       "      <th>garden</th>\n",
       "      <th>rent</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>Sachsen [SEP] central_heating [SEP] well_kept ...</td>\n",
       "      <td>-1.649237</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.844485</td>\n",
       "      <td>-0.552537</td>\n",
       "      <td>-1.773922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131248</th>\n",
       "      <td>Sachsen [SEP] central_heating [SEP] refurbishe...</td>\n",
       "      <td>-1.171890</td>\n",
       "      <td>0.931971</td>\n",
       "      <td>1.061725</td>\n",
       "      <td>1.453280</td>\n",
       "      <td>-1.537691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>Sachsen [SEP]  [SEP]  [SEP] NO_INFORMATION [SE...</td>\n",
       "      <td>-0.384375</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.905189</td>\n",
       "      <td>-0.552537</td>\n",
       "      <td>-1.634517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>Baden_Württemberg [SEP] self_contained_central...</td>\n",
       "      <td>-0.360172</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.447305</td>\n",
       "      <td>1.088776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87135</th>\n",
       "      <td>Hessen [SEP] central_heating [SEP] well_kept [...</td>\n",
       "      <td>0.686350</td>\n",
       "      <td>0.931971</td>\n",
       "      <td>0.971436</td>\n",
       "      <td>0.447305</td>\n",
       "      <td>-0.023496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcdfab44-a17e-44fc-a7a8-da779e424235')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dcdfab44-a17e-44fc-a7a8-da779e424235 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dcdfab44-a17e-44fc-a7a8-da779e424235');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xdgK-v2Y5K0",
    "outputId": "05556983-2d75-4f59-a7fd-70ac306dde65",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VECF6-jeY5NQ",
    "outputId": "24f2696b-5c3f-49d4-d611-898180ce7fcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another key parameter is our \"maximum sequence length\", which we will truncate or pad all of our samples to. Setting this to a higher value requires more memory and slows down training, so we want to see how short we can get away with.\n",
    "\n",
    "We'll run a pass over the dataset to find the longest sequence and use this to inform our choice. "
   ],
   "metadata": {
    "id": "F5W3-iVkafHO",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "analyze_lengths = True\n",
    "\n",
    "if analyze_lengths:\n",
    "    \n",
    "    seq_lens = []\n",
    "\n",
    "    print('Tokenizing all {:,} samples to measure lengths...'.format(len(text_combined)))\n",
    "\n",
    "    # For each of the samples...\n",
    "    for (i, text) in enumerate(text_combined):\n",
    "\n",
    "        # Print progress every 2k samples.\n",
    "        if ((i % 2000) == 0):\n",
    "            print('  {:>6,}'.format(i))\n",
    "\n",
    "        # Tokenize the text.\n",
    "        input_ids = tokenizer.encode(text)\n",
    "\n",
    "        # Store the length.\n",
    "        seq_lens.append(len(input_ids))\n",
    "\n",
    "    print('DONE.\\n')\n",
    "\n",
    "    print('Longest sequence: ', max(seq_lens))\n",
    "    print('Median:', round(np.median(seq_lens)))\n",
    "\n",
    "    # Plot a histogram of the rental prices.\n",
    "    ax = sns.histplot(seq_lens, bins=30)\n",
    "\n",
    "    t = ax.set_title('Histogram of Sequence Lengths')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kO1u8p6pY5P7",
    "outputId": "8107f6fb-ec12-4c09-ceb8-2f0bb4f3bc73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tokenizing all 217,017 samples to measure lengths...\n",
      "       0\n",
      "   2,000\n",
      "   4,000\n",
      "   6,000\n",
      "   8,000\n",
      "  10,000\n",
      "  12,000\n",
      "  14,000\n",
      "  16,000\n",
      "  18,000\n",
      "  20,000\n",
      "  22,000\n",
      "  24,000\n",
      "  26,000\n",
      "  28,000\n",
      "  30,000\n",
      "  32,000\n",
      "  34,000\n",
      "  36,000\n",
      "  38,000\n",
      "  40,000\n",
      "  42,000\n",
      "  44,000\n",
      "  46,000\n",
      "  48,000\n",
      "  50,000\n",
      "  52,000\n",
      "  54,000\n",
      "  56,000\n",
      "  58,000\n",
      "  60,000\n",
      "  62,000\n",
      "  64,000\n",
      "  66,000\n",
      "  68,000\n",
      "  70,000\n",
      "  72,000\n",
      "  74,000\n",
      "  76,000\n",
      "  78,000\n",
      "  80,000\n",
      "  82,000\n",
      "  84,000\n",
      "  86,000\n",
      "  88,000\n",
      "  90,000\n",
      "  92,000\n",
      "  94,000\n",
      "  96,000\n",
      "  98,000\n",
      "  100,000\n",
      "  102,000\n",
      "  104,000\n",
      "  106,000\n",
      "  108,000\n",
      "  110,000\n",
      "  112,000\n",
      "  114,000\n",
      "  116,000\n",
      "  118,000\n",
      "  120,000\n",
      "  122,000\n",
      "  124,000\n",
      "  126,000\n",
      "  128,000\n",
      "  130,000\n",
      "  132,000\n",
      "  134,000\n",
      "  136,000\n",
      "  138,000\n",
      "  140,000\n",
      "  142,000\n",
      "  144,000\n",
      "  146,000\n",
      "  148,000\n",
      "  150,000\n",
      "  152,000\n",
      "  154,000\n",
      "  156,000\n",
      "  158,000\n",
      "  160,000\n",
      "  162,000\n",
      "  164,000\n",
      "  166,000\n",
      "  168,000\n",
      "  170,000\n",
      "  172,000\n",
      "  174,000\n",
      "  176,000\n",
      "  178,000\n",
      "  180,000\n",
      "  182,000\n",
      "  184,000\n",
      "  186,000\n",
      "  188,000\n",
      "  190,000\n",
      "  192,000\n",
      "  194,000\n",
      "  196,000\n",
      "  198,000\n",
      "  200,000\n",
      "  202,000\n",
      "  204,000\n",
      "  206,000\n",
      "  208,000\n",
      "  210,000\n",
      "  212,000\n",
      "  214,000\n",
      "  216,000\n",
      "DONE.\n",
      "\n",
      "Longest sequence:  2823\n",
      "Median: 196\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm going to start with a max_len of 600, just to speed up training. We can try a longer length next."
   ],
   "metadata": {
    "id": "7z5uOUXTegTn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Specify the length to pad / truncate all sequences to.\n",
    "max_len = 400"
   ],
   "metadata": {
    "id": "ltqrGkFKeZw_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training Split**"
   ],
   "metadata": {
    "id": "oyjHbkCZeQGn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Re-split the dataset.\n",
    "test_df = data_df.loc[data_df.split == 'test']\n",
    "train_df = data_df.loc[data_df.split == 'train']\n",
    "\n",
    "print('After filtering:')\n",
    "print('  {:,} training samples'.format(len(train_df)))\n",
    "print('  {:,} test samples'.format(len(test_df)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJTPll63akRv",
    "outputId": "443752bf-188e-4531-982f-51330c0789c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "After filtering:\n",
      "  173,613 training samples\n",
      "  43,404 test samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can do the real tokenization and encoding.\n"
   ],
   "metadata": {
    "id": "iS5okUvDetLH",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "print('Encoding {:,} text samples...'.format(len(train_df)))\n",
    "\n",
    "num_done = 0\n",
    "\n",
    "# For each of the samples...\n",
    "for (row_i, row) in train_df.iterrows():\n",
    "\n",
    "    # Update every 2k samples.\n",
    "    if ((num_done % 2000) == 0):\n",
    "        print('  {:>6,}'.format(num_done))\n",
    "\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        row['text'],                  # Sentence to encode.\n",
    "                        max_length = max_len,  # Pad & truncate all sentences.\n",
    "                        truncation = True,\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    num_done += 1\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Szl8zK9OeX2j",
    "outputId": "d552618a-02ec-4aa6-f13c-4a087a753bca",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoding 173,613 text samples...\n",
      "       0\n",
      "   2,000\n",
      "   4,000\n",
      "   6,000\n",
      "   8,000\n",
      "  10,000\n",
      "  12,000\n",
      "  14,000\n",
      "  16,000\n",
      "  18,000\n",
      "  20,000\n",
      "  22,000\n",
      "  24,000\n",
      "  26,000\n",
      "  28,000\n",
      "  30,000\n",
      "  32,000\n",
      "  34,000\n",
      "  36,000\n",
      "  38,000\n",
      "  40,000\n",
      "  42,000\n",
      "  44,000\n",
      "  46,000\n",
      "  48,000\n",
      "  50,000\n",
      "  52,000\n",
      "  54,000\n",
      "  56,000\n",
      "  58,000\n",
      "  60,000\n",
      "  62,000\n",
      "  64,000\n",
      "  66,000\n",
      "  68,000\n",
      "  70,000\n",
      "  72,000\n",
      "  74,000\n",
      "  76,000\n",
      "  78,000\n",
      "  80,000\n",
      "  82,000\n",
      "  84,000\n",
      "  86,000\n",
      "  88,000\n",
      "  90,000\n",
      "  92,000\n",
      "  94,000\n",
      "  96,000\n",
      "  98,000\n",
      "  100,000\n",
      "  102,000\n",
      "  104,000\n",
      "  106,000\n",
      "  108,000\n",
      "  110,000\n",
      "  112,000\n",
      "  114,000\n",
      "  116,000\n",
      "  118,000\n",
      "  120,000\n",
      "  122,000\n",
      "  124,000\n",
      "  126,000\n",
      "  128,000\n",
      "  130,000\n",
      "  132,000\n",
      "  134,000\n",
      "  136,000\n",
      "  138,000\n",
      "  140,000\n",
      "  142,000\n",
      "  144,000\n",
      "  146,000\n",
      "  148,000\n",
      "  150,000\n",
      "  152,000\n",
      "  154,000\n",
      "  156,000\n",
      "  158,000\n",
      "  160,000\n",
      "  162,000\n",
      "  164,000\n",
      "  166,000\n",
      "  168,000\n",
      "  170,000\n",
      "  172,000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "print('DONE.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-uC12tLakU8",
    "outputId": "8dd610ea-95b4-4264-e353-5c3de3bb78e7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create PyTorch tensors for the labels and categorical features."
   ],
   "metadata": {
    "id": "gwd8g5NzfKb1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Tensor for labels.\n",
    "labels = torch.tensor(train_df['rent'].values)\n",
    "\n",
    "# Tensor for categorical features.\n",
    "categorical_feats = torch.tensor(train_df[col_info['cat_cols']].values, dtype=torch.float32)\n",
    "\n",
    "# Tensor for numerical features.\n",
    "numerical_feats = torch.tensor(train_df[col_info['num_cols']].values.astype('float'), dtype=torch.float32)"
   ],
   "metadata": {
    "id": "678ha9ytakXx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, categorical_feats, numerical_feats, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL_ezp3mY5dV",
    "outputId": "07b293a7-9572-4b52-c1ac-b58b60fef220",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "156,251 training samples\n",
      "17,362 validation samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to implement our model, we need to define our own BERT class based on `BertForSequenceClassification`.\n",
    "\n",
    "I named our custom class `BertConcatFeatures`. \n",
    "\n",
    "One component of our custom model is the multi-layer neural network (a.k.a. Multi-Layer Perceptron or \"MLP\") that we'll use on the output to generate our actual price prediction.  We'll define our `MLP` class first, then use it as a component within `BertConcatFeatures`.\n",
    "\n",
    "> *Why an MLP?* \n",
    "> Normally, with BERT we just use a simple linear classifier on the output. That's because BERT is a massive and powerful model, and is able to encode everything needed for a simple classification into the `[CLS]` embedding.\n",
    "> Here, though, we have some additional features outside of BERT, so we'll want a more sophisticated model on the output that's able to combine the different sources of information intelligently."
   ],
   "metadata": {
    "id": "9QQB1yP0faDX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is the definition of our MLP model, which we'll use on the output to generate our final prediction. \n"
   ],
   "metadata": {
    "id": "Gx5Hi5OJfoMV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"mlp can specify number of hidden layers and hidden layer channels\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_lyr=2,\n",
    "                 dropout_prob=0.5, return_layer_outs=False,\n",
    "                 hidden_channels=None, bn=False):\n",
    "        super().__init__()\n",
    "        self.out_dim = output_dim\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.return_layer_outs = return_layer_outs\n",
    "        if not hidden_channels:\n",
    "            hidden_channels = [input_dim for _ in range(num_hidden_lyr)]\n",
    "        elif len(hidden_channels) != num_hidden_lyr:\n",
    "            raise ValueError(\n",
    "                \"number of hidden layers should be the same as the lengh of hidden_channels\")\n",
    "        self.layer_channels = [input_dim] + hidden_channels + [output_dim]\n",
    "        self.act_name = 'relu'\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layers = nn.ModuleList(list(\n",
    "            map(self.weight_init, [nn.Linear(self.layer_channels[i], self.layer_channels[i + 1])\n",
    "                                   for i in range(len(self.layer_channels) - 2)])))\n",
    "        final_layer = nn.Linear(self.layer_channels[-2], self.layer_channels[-1])\n",
    "        self.weight_init(final_layer,   activation='linear')\n",
    "        self.layers.append(final_layer)\n",
    "\n",
    "        self.bn = bn\n",
    "        if self.bn:\n",
    "            self.bn = nn.ModuleList([torch.nn.BatchNorm1d(dim) for dim in self.layer_channels[1:-1]])\n",
    "\n",
    "    def weight_init(self, m, activation=None):\n",
    "        if activation is None:\n",
    "            activation = self.act_name\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain(activation))\n",
    "        return m\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: the input features\n",
    "        :return: tuple containing output of MLP,\n",
    "                and list of inputs and outputs at every layer\n",
    "        \"\"\"\n",
    "        layer_inputs = [x]\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            input = layer_inputs[-1]\n",
    "            if layer == self.layers[-1]:\n",
    "                layer_inputs.append(layer(input))\n",
    "            else:\n",
    "                if self.bn:\n",
    "                    output = self.activation(self.bn[i](layer(input)))\n",
    "                else:\n",
    "                    output = self.activation(layer(input))\n",
    "                layer_inputs.append(self.dropout(output))\n",
    "\n",
    "        # model.store_layer_output(self, layer_inputs[-1])\n",
    "        if self.return_layer_outs:\n",
    "            return layer_inputs[-1], layer_inputs\n",
    "        else:\n",
    "            return layer_inputs[-1]\n"
   ],
   "metadata": {
    "id": "acAagUPYfljJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "class BertConcatFeatures(BertForSequenceClassification):\n",
    "    \"\"\"\n",
    "    A model for classification or regression which combines text, categorical,\n",
    "    and numerical features. The text features are processed with BERT. All\n",
    "    features are concatenated into a single vector, which is fed into an MLP\n",
    "    for final classification / regression.\n",
    "\n",
    "    This class expects a transformers.BertConfig object, and the config object\n",
    "    needs to have three additional properties manually added to it:\n",
    "      `text_feat_dim` - The length of the BERT vector.\n",
    "      `cat_feat_dim` - The number of categorical features.\n",
    "      `numerical_feat_dim` - The number of numerical features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        # ====================\n",
    "        #     BERT Setup\n",
    "        # ====================\n",
    "\n",
    "        # Call the constructor for the huggingface `BertForSequenceClassification` \n",
    "        # class, which will do all of the BERT-related setup. The resulting BERT\n",
    "        # model is stored in `self.bert`. \n",
    "        super().__init__(config)\n",
    "        \n",
    "        # ==================================\n",
    "        #     Feature Combination Setup\n",
    "        # ==================================\n",
    "\n",
    "        # Store the number of labels, which tells us whether this is a \n",
    "        # classification or regression task.\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        # Calculate the combined vector length. \n",
    "        combined_feat_dim = config.text_feat_dim + \\\n",
    "                            config.cat_feat_dim + \\\n",
    "                            config.numerical_feat_dim\n",
    "\n",
    "        # Create a batch normalizer for the numerical features.\n",
    "        self.num_bn = nn.BatchNorm1d(config.numerical_feat_dim)\n",
    "\n",
    "        # ====================\n",
    "        #     MLP Setup\n",
    "        # ====================\n",
    "\n",
    "        # To setup the MLP, we need to specify the number of layers and the\n",
    "        # number of neurons in each layer. The MultiModal-Toolkit has a formula\n",
    "        # for picking these dimensions. Each layer of the MLP has 1/4th the \n",
    "        # number of neurons as the previous one. \n",
    "        \n",
    "        # Dimensions of each MLP layer.\n",
    "        dims = []\n",
    "\n",
    "        # Starting with the combined feature vector length...\n",
    "        dim = combined_feat_dim\n",
    "\n",
    "        # Keep dividing by 4 until we drop below the number of outputs the MLP\n",
    "        # needs to have. \n",
    "        while True:\n",
    "            \n",
    "            # Divide by 4 and truncate to an integer.\n",
    "            dim = dim // 4\n",
    "            \n",
    "            # If the resulting layer size would be smaller than the number of \n",
    "            # outputs, then we're done.\n",
    "            if dim <= self.num_labels:\n",
    "                break\n",
    "            \n",
    "            # Otherwise, store this as the next layer size.\n",
    "            dims.append(int(dim))\n",
    "\n",
    "        # Print out the resulting MLP.                \n",
    "        print('MLP layer sizes:')\n",
    "        print('  Input:', combined_feat_dim)\n",
    "        print('  Hidden:', dims)\n",
    "        print('  Output:', self.num_labels)\n",
    "        print('')\n",
    "\n",
    "        # Construct the MLP, specifying the number of inputs, outputs, and the\n",
    "        # layer sizes.\n",
    "        self.mlp = MLP(combined_feat_dim,\n",
    "                        self.num_labels,\n",
    "                        num_hidden_lyr=len(dims),\n",
    "                        dropout_prob=0.1,\n",
    "                        hidden_channels=dims,\n",
    "                        bn=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        class_weights=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        cat_feats=None,\n",
    "        numerical_feats=None\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Perform a forward pass of our model.\n",
    "        \n",
    "        This has the same inputs as `forward` in `BertForSequenceClassification`,\n",
    "        but with two extra parameters:\n",
    "          `cat_feats` - Tensor of categorical features.\n",
    "          `numerical_feats` - Tensor of numerical features.  \n",
    "        \"\"\"\n",
    "        \n",
    "        # ====================\n",
    "        #        BERT\n",
    "        # ====================\n",
    "       \n",
    "        # Run the text through the BERT model. Invoking `self.bert` returns \n",
    "        # outputs from the encoding layers, and not from the final classifier.\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "        \n",
    "        # outputs[0] - All of the output embeddings from BERT\n",
    "        # outputs[1] - The [CLS] token embedding, with some additional \"pooling\"\n",
    "        #              done.\n",
    "        cls = outputs[1]\n",
    "        \n",
    "        # Apply dropout to the CLS embedding.\n",
    "        cls = self.dropout(cls)\n",
    "\n",
    "        # ==========================\n",
    "        #    Concatenate Features\n",
    "        # ==========================        \n",
    "\n",
    "        # Apply batch normalization to the numerical features.        \n",
    "        numerical_feats = self.num_bn(numerical_feats)\n",
    "    \n",
    "        # Object sizes:\n",
    "        #             cls   [batch size  x   768]\n",
    "        # numerical_feats   [batch size  x   # numerical features]\n",
    "        #       cat_feats   [batch size  x   # categorical features]\n",
    "    \n",
    "        # Simply concatenate everything into one vector.\n",
    "        # For example, if we have 6 categ. and 5 numer. features, then the\n",
    "        # result has 768 + 6 + 5 = 779 features.\n",
    "        combined_feats = torch.cat((cls, cat_feats, numerical_feats),\n",
    "                                    dim=1)\n",
    "        \n",
    "        # ====================================\n",
    "        #    Output Classifier / Regression\n",
    "        # ====================================        \n",
    "\n",
    "        # Run the the samples through the MLP.\n",
    "        logits = self.mlp(combined_feats)\n",
    "\n",
    "        # TODO - Not sure what's going on with the outputs...\n",
    "\n",
    "        if type(logits) is tuple:\n",
    "            logits, classifier_layer_outputs = logits[0], logits[1]\n",
    "\n",
    "        else:  # simple classifier\n",
    "            classifier_layer_outputs = [combined_feats, logits]\n",
    "        \n",
    "        # =================\n",
    "        #       Loss\n",
    "        # =================\n",
    "\n",
    "        # Calculate loss, but only if labels were provided.\n",
    "        # (Labels aren't provided at test time).\n",
    "        if labels is not None:\n",
    "\n",
    "            # Regression\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "\n",
    "                labels = labels.float()\n",
    "\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            \n",
    "            # Classification\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=class_weights)\n",
    "                \n",
    "                labels = labels.long()\n",
    "                \n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        # If no labels are provided, set the loss to 'None'.\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        # Put the results into a Dictionary to return.\n",
    "        results = {'loss': loss, \n",
    "                   'logits': logits,\n",
    "                   'classifier_layer_outputs': classifier_layer_outputs}\n",
    "\n",
    "        return results\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Q6YY90cXfyuQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we'll use our custom BERT class and load Google's pre-trained version of BERT.\n",
    "\n",
    "The first step is to connect the GPU to PyTorch."
   ],
   "metadata": {
    "id": "hweMS_1DgQhv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Print out what GPU we've got.\n",
    "    print('There are %d GPU(s) available:\\n' % torch.cuda.device_count())\n",
    "    print('    ', torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\") \n",
    "\n",
    "# If not, you could use the CPU, but this isn't recommended!\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kT4RKlRygP0z",
    "outputId": "5ef5ca30-be29-4a8b-ef08-543b67003c7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 1 GPU(s) available:\n",
      "\n",
      "     Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we'll initialize our custom class. This involves loading the pre-trained weights of the BERT model as well as defining our output MLP and initializing its weights. \n",
    "\n",
    "In order to set up the MLP, we'll need to know the total feature dimensions, so we'll specify these using an instance of the BertConfig class.\n",
    "\n",
    "In the output of this cell, note that it prints the size of each of the hidden layers in the MLP."
   ],
   "metadata": {
    "id": "MKdaBfT6gZf6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "# We'll need to a use a \"BertConfig\" object from the transformers library to\n",
    "# specify our parameters. \n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "# First, specify the ordinary BERT parameters by taking them from the \n",
    "# 'bert-base-uncased' model. \n",
    "# Also set the number of labels.\n",
    "config = BertConfig.from_pretrained(\n",
    "        'bert-base-german-cased',\n",
    "        num_labels=1, # The number of output labels--1 for regression.\n",
    "    )\n",
    "\n",
    "# To set up the MLP, we need to know the combined vector length that will be\n",
    "# sent into it. \n",
    "\n",
    "# Pass in the number of numerical and categorical features.\n",
    "config.numerical_feat_dim = numerical_feats.size()[1]\n",
    "config.cat_feat_dim = categorical_feats.size()[1]\n",
    "\n",
    "# Pass in the size of the text embedding.\n",
    "# The text feature dimension is the \"hidden_size\" parameter which \n",
    "# comes from BertConfig. The length is 768 in BERT-base (and most other BERT\n",
    "# models).\n",
    "config.text_feat_dim = config.hidden_size # 768\n",
    "\n",
    "# Now we're ready to do the actual set up of our model! Note that we're passing\n",
    "# in the config object here.\n",
    "model = BertConcatFeatures.from_pretrained(\n",
    "    \"bert-base-german-cased\",\n",
    "    config = config\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "desc = model.cuda()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ME5Qc2nZfQra",
    "outputId": "7329bf3e-fc1d-41bd-ab95-6d01620208d6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLP layer sizes:\n",
      "  Input: 779\n",
      "  Hidden: [194, 48, 12, 3]\n",
      "  Output: 1\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertConcatFeatures: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertConcatFeatures from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertConcatFeatures from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertConcatFeatures were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['mlp.layers.1.bias', 'mlp.layers.2.weight', 'mlp.bn.0.running_var', 'classifier.bias', 'mlp.layers.4.bias', 'mlp.bn.0.running_mean', 'mlp.bn.1.running_mean', 'mlp.layers.3.bias', 'mlp.bn.3.running_mean', 'mlp.bn.1.running_var', 'mlp.bn.2.weight', 'mlp.bn.3.running_var', 'mlp.bn.2.running_var', 'mlp.bn.3.num_batches_tracked', 'num_bn.bias', 'mlp.layers.1.weight', 'mlp.layers.3.weight', 'mlp.bn.0.num_batches_tracked', 'mlp.bn.1.num_batches_tracked', 'mlp.bn.0.bias', 'mlp.bn.2.bias', 'mlp.bn.3.weight', 'mlp.layers.2.bias', 'mlp.bn.1.weight', 'mlp.bn.1.bias', 'num_bn.running_var', 'mlp.bn.2.running_mean', 'mlp.bn.3.bias', 'mlp.bn.2.num_batches_tracked', 'num_bn.weight', 'classifier.weight', 'mlp.layers.0.bias', 'num_bn.num_batches_tracked', 'num_bn.running_mean', 'mlp.layers.0.weight', 'mlp.layers.4.weight', 'mlp.bn.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Larger batch sizes tend to be better, and we can fit this in memory.\n",
    "batch_size = 16\n",
    "\n",
    "# This is the learning rate specified in Ken's configuration\n",
    "learning_rate = 3e-3\n",
    "\n",
    "# Number of training epochs. \n",
    "epochs = 2\n",
    "\n",
    "# Print out the max_len for reference. To change this, you'd need to set it\n",
    "# back in section 3 prior to the tokenization and encoding of the text.\n",
    "print('Using maximum sequence length:', max_len)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jj-Hq-V7fQuc",
    "outputId": "ed8d2052-ddec-4d46-875f-5c720c131f00",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using maximum sequence length: 400\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "metadata": {
    "id": "CNKazbZqfQxA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8 \n",
    "                )\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPRpJ9f9Y5fW",
    "outputId": "2c8bebc8-ceba-4bbd-f447-941ac2ca5c2a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples!)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "metadata": {
    "id": "mQ7EZi0DhwRN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ],
   "metadata": {
    "id": "ht3tonfIhwT2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_categ_feats = batch[1].to(device)\n",
    "        b_numer_feats = batch[2].to(device) \n",
    "        b_input_mask = batch[3].to(device)\n",
    "        b_labels = batch[4].to(device)\n",
    "\n",
    "        # Clear prior gradients. \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. \n",
    "        # This will return the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       cat_feats = b_categ_feats,\n",
    "                       numerical_feats = b_numer_feats)\n",
    "\n",
    "        loss = result['loss']\n",
    "        logits = result['logits']\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    # Include the batch size so that we are looking at the average per-sample\n",
    "    # loss.\n",
    "    avg_train_loss = total_train_loss / (len(train_dataloader) * batch_size)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_categ_feats = batch[1].to(device) # TODO - Comment...\n",
    "        b_numer_feats = batch[2].to(device) \n",
    "        b_input_mask = batch[3].to(device)\n",
    "        b_labels = batch[4].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           cat_feats = b_categ_feats,\n",
    "                           numerical_feats = b_numer_feats)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result['loss']\n",
    "        logits = result['logits']\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        prices = b_labels.to('cpu').numpy()        \n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / (len(validation_dataloader) * batch_size)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XK876nuhwWC",
    "outputId": "9916fe0c-c004-4a7c-ba68-b85201fec97a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch   100  of  9,766.    Elapsed: 0:01:49.\n",
      "  Batch   200  of  9,766.    Elapsed: 0:03:48.\n",
      "  Batch   300  of  9,766.    Elapsed: 0:05:47.\n",
      "  Batch   400  of  9,766.    Elapsed: 0:07:45.\n",
      "  Batch   500  of  9,766.    Elapsed: 0:09:44.\n",
      "  Batch   600  of  9,766.    Elapsed: 0:11:42.\n",
      "  Batch   700  of  9,766.    Elapsed: 0:13:41.\n",
      "  Batch   800  of  9,766.    Elapsed: 0:15:39.\n",
      "  Batch   900  of  9,766.    Elapsed: 0:17:37.\n",
      "  Batch 1,000  of  9,766.    Elapsed: 0:19:36.\n",
      "  Batch 1,100  of  9,766.    Elapsed: 0:21:34.\n",
      "  Batch 1,200  of  9,766.    Elapsed: 0:23:32.\n",
      "  Batch 1,300  of  9,766.    Elapsed: 0:25:30.\n",
      "  Batch 1,400  of  9,766.    Elapsed: 0:27:29.\n",
      "  Batch 1,500  of  9,766.    Elapsed: 0:29:27.\n",
      "  Batch 1,600  of  9,766.    Elapsed: 0:31:26.\n",
      "  Batch 1,700  of  9,766.    Elapsed: 0:33:24.\n",
      "  Batch 1,800  of  9,766.    Elapsed: 0:35:23.\n",
      "  Batch 1,900  of  9,766.    Elapsed: 0:37:21.\n",
      "  Batch 2,000  of  9,766.    Elapsed: 0:39:20.\n",
      "  Batch 2,100  of  9,766.    Elapsed: 0:41:18.\n",
      "  Batch 2,200  of  9,766.    Elapsed: 0:43:16.\n",
      "  Batch 2,300  of  9,766.    Elapsed: 0:45:15.\n",
      "  Batch 2,400  of  9,766.    Elapsed: 0:47:13.\n",
      "  Batch 2,500  of  9,766.    Elapsed: 0:49:12.\n",
      "  Batch 2,600  of  9,766.    Elapsed: 0:51:10.\n",
      "  Batch 2,700  of  9,766.    Elapsed: 0:53:08.\n",
      "  Batch 2,800  of  9,766.    Elapsed: 0:55:07.\n",
      "  Batch 2,900  of  9,766.    Elapsed: 0:57:06.\n",
      "  Batch 3,000  of  9,766.    Elapsed: 0:59:04.\n",
      "  Batch 3,100  of  9,766.    Elapsed: 1:01:02.\n",
      "  Batch 3,200  of  9,766.    Elapsed: 1:03:01.\n",
      "  Batch 3,300  of  9,766.    Elapsed: 1:04:59.\n",
      "  Batch 3,400  of  9,766.    Elapsed: 1:06:57.\n",
      "  Batch 3,500  of  9,766.    Elapsed: 1:08:56.\n",
      "  Batch 3,600  of  9,766.    Elapsed: 1:10:54.\n",
      "  Batch 3,700  of  9,766.    Elapsed: 1:12:52.\n",
      "  Batch 3,800  of  9,766.    Elapsed: 1:14:51.\n",
      "  Batch 3,900  of  9,766.    Elapsed: 1:16:49.\n",
      "  Batch 4,000  of  9,766.    Elapsed: 1:18:47.\n",
      "  Batch 4,100  of  9,766.    Elapsed: 1:20:46.\n",
      "  Batch 4,200  of  9,766.    Elapsed: 1:22:44.\n",
      "  Batch 4,300  of  9,766.    Elapsed: 1:24:42.\n",
      "  Batch 4,400  of  9,766.    Elapsed: 1:26:40.\n",
      "  Batch 4,500  of  9,766.    Elapsed: 1:28:39.\n",
      "  Batch 4,600  of  9,766.    Elapsed: 1:30:37.\n",
      "  Batch 4,700  of  9,766.    Elapsed: 1:32:35.\n",
      "  Batch 4,800  of  9,766.    Elapsed: 1:34:33.\n",
      "  Batch 4,900  of  9,766.    Elapsed: 1:36:31.\n",
      "  Batch 5,000  of  9,766.    Elapsed: 1:38:29.\n",
      "  Batch 5,100  of  9,766.    Elapsed: 1:40:27.\n",
      "  Batch 5,200  of  9,766.    Elapsed: 1:42:25.\n",
      "  Batch 5,300  of  9,766.    Elapsed: 1:44:24.\n",
      "  Batch 5,400  of  9,766.    Elapsed: 1:46:22.\n",
      "  Batch 5,500  of  9,766.    Elapsed: 1:48:20.\n",
      "  Batch 5,600  of  9,766.    Elapsed: 1:50:19.\n",
      "  Batch 5,700  of  9,766.    Elapsed: 1:52:17.\n",
      "  Batch 5,800  of  9,766.    Elapsed: 1:54:15.\n",
      "  Batch 5,900  of  9,766.    Elapsed: 1:56:14.\n",
      "  Batch 6,000  of  9,766.    Elapsed: 1:58:12.\n",
      "  Batch 6,100  of  9,766.    Elapsed: 2:00:10.\n",
      "  Batch 6,200  of  9,766.    Elapsed: 2:02:09.\n",
      "  Batch 6,300  of  9,766.    Elapsed: 2:04:08.\n",
      "  Batch 6,400  of  9,766.    Elapsed: 2:06:06.\n",
      "  Batch 6,500  of  9,766.    Elapsed: 2:08:04.\n",
      "  Batch 6,600  of  9,766.    Elapsed: 2:10:02.\n",
      "  Batch 6,700  of  9,766.    Elapsed: 2:12:00.\n",
      "  Batch 6,800  of  9,766.    Elapsed: 2:13:58.\n",
      "  Batch 6,900  of  9,766.    Elapsed: 2:15:56.\n",
      "  Batch 7,000  of  9,766.    Elapsed: 2:17:55.\n",
      "  Batch 7,100  of  9,766.    Elapsed: 2:19:53.\n",
      "  Batch 7,200  of  9,766.    Elapsed: 2:21:51.\n",
      "  Batch 7,300  of  9,766.    Elapsed: 2:23:49.\n",
      "  Batch 7,400  of  9,766.    Elapsed: 2:25:47.\n",
      "  Batch 7,500  of  9,766.    Elapsed: 2:27:45.\n",
      "  Batch 7,600  of  9,766.    Elapsed: 2:29:44.\n",
      "  Batch 7,700  of  9,766.    Elapsed: 2:31:42.\n",
      "  Batch 7,800  of  9,766.    Elapsed: 2:33:40.\n",
      "  Batch 7,900  of  9,766.    Elapsed: 2:35:39.\n",
      "  Batch 8,000  of  9,766.    Elapsed: 2:37:37.\n",
      "  Batch 8,100  of  9,766.    Elapsed: 2:39:35.\n",
      "  Batch 8,200  of  9,766.    Elapsed: 2:41:34.\n",
      "  Batch 8,300  of  9,766.    Elapsed: 2:43:32.\n",
      "  Batch 8,400  of  9,766.    Elapsed: 2:45:30.\n",
      "  Batch 8,500  of  9,766.    Elapsed: 2:47:29.\n",
      "  Batch 8,600  of  9,766.    Elapsed: 2:49:26.\n",
      "  Batch 8,700  of  9,766.    Elapsed: 2:51:25.\n",
      "  Batch 8,800  of  9,766.    Elapsed: 2:53:23.\n",
      "  Batch 8,900  of  9,766.    Elapsed: 2:55:21.\n",
      "  Batch 9,000  of  9,766.    Elapsed: 2:57:20.\n",
      "  Batch 9,100  of  9,766.    Elapsed: 2:59:18.\n",
      "  Batch 9,200  of  9,766.    Elapsed: 3:01:16.\n",
      "  Batch 9,300  of  9,766.    Elapsed: 3:03:14.\n",
      "  Batch 9,400  of  9,766.    Elapsed: 3:05:12.\n",
      "  Batch 9,500  of  9,766.    Elapsed: 3:07:10.\n",
      "  Batch 9,600  of  9,766.    Elapsed: 3:09:08.\n",
      "  Batch 9,700  of  9,766.    Elapsed: 3:11:07.\n",
      "\n",
      "  Average training loss: 19462.26\n",
      "  Training epcoh took: 3:12:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 4492.15\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch   100  of  9,766.    Elapsed: 0:01:58.\n",
      "  Batch   200  of  9,766.    Elapsed: 0:03:56.\n",
      "  Batch   300  of  9,766.    Elapsed: 0:05:54.\n",
      "  Batch   400  of  9,766.    Elapsed: 0:07:52.\n",
      "  Batch   500  of  9,766.    Elapsed: 0:09:50.\n",
      "  Batch   600  of  9,766.    Elapsed: 0:11:47.\n",
      "  Batch   700  of  9,766.    Elapsed: 0:13:45.\n",
      "  Batch   800  of  9,766.    Elapsed: 0:15:43.\n",
      "  Batch   900  of  9,766.    Elapsed: 0:17:41.\n",
      "  Batch 1,000  of  9,766.    Elapsed: 0:19:38.\n",
      "  Batch 1,100  of  9,766.    Elapsed: 0:21:36.\n",
      "  Batch 1,200  of  9,766.    Elapsed: 0:23:34.\n",
      "  Batch 1,300  of  9,766.    Elapsed: 0:25:32.\n",
      "  Batch 1,400  of  9,766.    Elapsed: 0:27:30.\n",
      "  Batch 1,500  of  9,766.    Elapsed: 0:29:28.\n",
      "  Batch 1,600  of  9,766.    Elapsed: 0:31:25.\n",
      "  Batch 1,700  of  9,766.    Elapsed: 0:33:23.\n",
      "  Batch 1,800  of  9,766.    Elapsed: 0:35:21.\n",
      "  Batch 1,900  of  9,766.    Elapsed: 0:37:18.\n",
      "  Batch 2,000  of  9,766.    Elapsed: 0:39:16.\n",
      "  Batch 2,100  of  9,766.    Elapsed: 0:41:14.\n",
      "  Batch 2,200  of  9,766.    Elapsed: 0:43:12.\n",
      "  Batch 2,300  of  9,766.    Elapsed: 0:45:10.\n",
      "  Batch 2,400  of  9,766.    Elapsed: 0:47:07.\n",
      "  Batch 2,500  of  9,766.    Elapsed: 0:49:05.\n",
      "  Batch 2,600  of  9,766.    Elapsed: 0:51:03.\n",
      "  Batch 2,700  of  9,766.    Elapsed: 0:53:01.\n",
      "  Batch 2,800  of  9,766.    Elapsed: 0:54:58.\n",
      "  Batch 2,900  of  9,766.    Elapsed: 0:56:56.\n",
      "  Batch 3,000  of  9,766.    Elapsed: 0:58:54.\n",
      "  Batch 3,100  of  9,766.    Elapsed: 1:00:52.\n",
      "  Batch 3,200  of  9,766.    Elapsed: 1:02:50.\n",
      "  Batch 3,300  of  9,766.    Elapsed: 1:04:48.\n",
      "  Batch 3,400  of  9,766.    Elapsed: 1:06:45.\n",
      "  Batch 3,500  of  9,766.    Elapsed: 1:08:44.\n",
      "  Batch 3,600  of  9,766.    Elapsed: 1:10:42.\n",
      "  Batch 3,700  of  9,766.    Elapsed: 1:12:39.\n",
      "  Batch 3,800  of  9,766.    Elapsed: 1:14:37.\n",
      "  Batch 3,900  of  9,766.    Elapsed: 1:16:35.\n",
      "  Batch 4,000  of  9,766.    Elapsed: 1:18:33.\n",
      "  Batch 4,100  of  9,766.    Elapsed: 1:20:31.\n",
      "  Batch 4,200  of  9,766.    Elapsed: 1:22:29.\n",
      "  Batch 4,300  of  9,766.    Elapsed: 1:24:26.\n",
      "  Batch 4,400  of  9,766.    Elapsed: 1:26:24.\n",
      "  Batch 4,500  of  9,766.    Elapsed: 1:28:22.\n",
      "  Batch 4,600  of  9,766.    Elapsed: 1:30:20.\n",
      "  Batch 4,700  of  9,766.    Elapsed: 1:32:18.\n",
      "  Batch 4,800  of  9,766.    Elapsed: 1:34:16.\n",
      "  Batch 4,900  of  9,766.    Elapsed: 1:36:14.\n",
      "  Batch 5,000  of  9,766.    Elapsed: 1:38:12.\n",
      "  Batch 5,100  of  9,766.    Elapsed: 1:40:10.\n",
      "  Batch 5,200  of  9,766.    Elapsed: 1:42:08.\n",
      "  Batch 5,300  of  9,766.    Elapsed: 1:44:06.\n",
      "  Batch 5,400  of  9,766.    Elapsed: 1:46:04.\n",
      "  Batch 5,500  of  9,766.    Elapsed: 1:48:02.\n",
      "  Batch 5,600  of  9,766.    Elapsed: 1:50:00.\n",
      "  Batch 5,700  of  9,766.    Elapsed: 1:51:58.\n",
      "  Batch 5,800  of  9,766.    Elapsed: 1:53:56.\n",
      "  Batch 5,900  of  9,766.    Elapsed: 1:55:54.\n",
      "  Batch 6,000  of  9,766.    Elapsed: 1:57:52.\n",
      "  Batch 6,100  of  9,766.    Elapsed: 1:59:49.\n",
      "  Batch 6,200  of  9,766.    Elapsed: 2:01:47.\n",
      "  Batch 6,300  of  9,766.    Elapsed: 2:03:45.\n",
      "  Batch 6,400  of  9,766.    Elapsed: 2:05:43.\n",
      "  Batch 6,500  of  9,766.    Elapsed: 2:07:41.\n",
      "  Batch 6,600  of  9,766.    Elapsed: 2:09:39.\n",
      "  Batch 6,700  of  9,766.    Elapsed: 2:11:37.\n",
      "  Batch 6,800  of  9,766.    Elapsed: 2:13:35.\n",
      "  Batch 6,900  of  9,766.    Elapsed: 2:15:33.\n",
      "  Batch 7,000  of  9,766.    Elapsed: 2:17:31.\n",
      "  Batch 7,100  of  9,766.    Elapsed: 2:19:29.\n",
      "  Batch 7,200  of  9,766.    Elapsed: 2:21:27.\n",
      "  Batch 7,300  of  9,766.    Elapsed: 2:23:25.\n",
      "  Batch 7,400  of  9,766.    Elapsed: 2:25:23.\n",
      "  Batch 7,500  of  9,766.    Elapsed: 2:27:21.\n",
      "  Batch 7,600  of  9,766.    Elapsed: 2:29:18.\n",
      "  Batch 7,700  of  9,766.    Elapsed: 2:31:16.\n",
      "  Batch 7,800  of  9,766.    Elapsed: 2:33:14.\n",
      "  Batch 7,900  of  9,766.    Elapsed: 2:35:12.\n",
      "  Batch 8,000  of  9,766.    Elapsed: 2:37:10.\n",
      "  Batch 8,100  of  9,766.    Elapsed: 2:39:08.\n",
      "  Batch 8,200  of  9,766.    Elapsed: 2:41:05.\n",
      "  Batch 8,300  of  9,766.    Elapsed: 2:43:03.\n",
      "  Batch 8,400  of  9,766.    Elapsed: 2:45:01.\n",
      "  Batch 8,500  of  9,766.    Elapsed: 2:46:59.\n",
      "  Batch 8,600  of  9,766.    Elapsed: 2:48:57.\n",
      "  Batch 8,700  of  9,766.    Elapsed: 2:50:55.\n",
      "  Batch 8,800  of  9,766.    Elapsed: 2:52:52.\n",
      "  Batch 8,900  of  9,766.    Elapsed: 2:54:51.\n",
      "  Batch 9,000  of  9,766.    Elapsed: 2:56:48.\n",
      "  Batch 9,100  of  9,766.    Elapsed: 2:58:46.\n",
      "  Batch 9,200  of  9,766.    Elapsed: 3:00:44.\n",
      "  Batch 9,300  of  9,766.    Elapsed: 3:02:42.\n",
      "  Batch 9,400  of  9,766.    Elapsed: 3:04:40.\n",
      "  Batch 9,500  of  9,766.    Elapsed: 3:06:38.\n",
      "  Batch 9,600  of  9,766.    Elapsed: 3:08:36.\n",
      "  Batch 9,700  of  9,766.    Elapsed: 3:10:33.\n",
      "\n",
      "  Average training loss: 7103.88\n",
      "  Training epcoh took: 3:11:51\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 4351.63\n",
      "  Validation took: 0:07:23\n",
      "\n",
      "Training complete!\n",
      "Total training took 6:39:02 (h:mm:ss)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Results"
   ],
   "metadata": {
    "id": "Ov5qOiwxiBQO",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's view the summary of the training process."
   ],
   "metadata": {
    "id": "jkGAtAHKiEpV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap (doesn't seem to work in Colab).\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "YCRG6WPPiAyi",
    "outputId": "3ca780ca-8599-490e-c1ef-afe96cfac022",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Training Loss  Valid. Loss Training Time Validation Time\n",
       "epoch                                                          \n",
       "1           19462.26      4492.15       3:12:24         0:07:23\n",
       "2            7103.88      4351.63       3:11:51         0:07:23"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-f24e9c32-d135-4dc3-973c-9b14c46e737d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19462.26</td>\n",
       "      <td>4492.15</td>\n",
       "      <td>3:12:24</td>\n",
       "      <td>0:07:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7103.88</td>\n",
       "      <td>4351.63</td>\n",
       "      <td>3:11:51</td>\n",
       "      <td>0:07:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f24e9c32-d135-4dc3-973c-9b14c46e737d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f24e9c32-d135-4dc3-973c-9b14c46e737d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f24e9c32-d135-4dc3-973c-9b14c46e737d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "a_Fhi4v6iHti",
    "outputId": "ad21c59f-0592-497a-f2ec-cd5a8e6fc9f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "id": "E4q8Bxp7c0vN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Test Samples"
   ],
   "metadata": {
    "id": "FOM7jGO0dAnF",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pre-processing of the categorical and numerical features was done on the full dataset, and then we split it back into training and test sets lately. \n",
    "\n",
    "The one step we still need to do here is to tokenize and encode the text features for BERT. "
   ],
   "metadata": {
    "id": "-UfKqvnCdDF6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're ready to apply our fine-tuned model to the test set and see how we score."
   ],
   "metadata": {
    "id": "VyT6X24sc6fA",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "print('Encoding {:,} text samples...'.format(len(test_df)))\n",
    "\n",
    "num_done = 0\n",
    "\n",
    "# For each of the samples...\n",
    "for (row_i, row) in test_df.iterrows():\n",
    "\n",
    "    # Update every 2k samples.\n",
    "    if ((num_done % 2000) == 0):\n",
    "        print('  {:>6,}'.format(num_done))\n",
    "\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        row['text'],                  # Sentence to encode.\n",
    "                        max_length = max_len,  # Pad & truncate all sentences.\n",
    "                        truncation = True,\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    num_done += 1\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "print('DONE.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ci39FSMJiTls",
    "outputId": "352f0cd0-b1ed-4a0f-af51-fb8cdcb87aac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoding 43,404 text samples...\n",
      "       0\n",
      "   2,000\n",
      "   4,000\n",
      "   6,000\n",
      "   8,000\n",
      "  10,000\n",
      "  12,000\n",
      "  14,000\n",
      "  16,000\n",
      "  18,000\n",
      "  20,000\n",
      "  22,000\n",
      "  24,000\n",
      "  26,000\n",
      "  28,000\n",
      "  30,000\n",
      "  32,000\n",
      "  34,000\n",
      "  36,000\n",
      "  38,000\n",
      "  40,000\n",
      "  42,000\n",
      "DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Tensor for labels.\n",
    "labels = torch.tensor(test_df['rent'].values)\n",
    "\n",
    "# Tensor for categorical features.\n",
    "categorical_feats = torch.tensor(test_df[col_info['cat_cols']].values, dtype=torch.float32)\n",
    "\n",
    "# Tensor for numerical features.\n",
    "numerical_feats = torch.tensor(test_df[col_info['num_cols']].values.astype('float'), dtype=torch.float32)"
   ],
   "metadata": {
    "id": "XE6Awa2BiYQi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "test_dataset = TensorDataset(input_ids, categorical_feats, numerical_feats, attention_masks, labels)\n"
   ],
   "metadata": {
    "id": "2lFL6SHPicTL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Test Set"
   ],
   "metadata": {
    "id": "020EYAvKdZxm",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're ready to score our trained model against the test set!\n",
    "\n",
    "The below cell will generate all of the predictions."
   ],
   "metadata": {
    "id": "TUrrk1nOdc4Y",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a DataLoader to batch our test samples for us. We'll use a sequential\n",
    "# sampler this time--don't need this to be random!\n",
    "prediction_sampler = SequentialSampler(test_dataset)\n",
    "prediction_dataloader = DataLoader(test_dataset, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_categ_feats, b_numer_feats, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     cat_feats = b_categ_feats,\n",
    "                     numerical_feats = b_numer_feats)\n",
    "\n",
    "\n",
    "  logits = result['logits']\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1DzXlKqifrM",
    "outputId": "7090dc39-7b22-4dc0-ef20-2e200875837d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting labels for 43,404 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ],
   "metadata": {
    "id": "CAg2rmrMiiPF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Results"
   ],
   "metadata": {
    "id": "AqtWMygjdlLn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can score the results!\n",
    "The first is the Mean Absolute Error (MAE).\n"
   ],
   "metadata": {
    "id": "mPZSOFaSdnCK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Subtract the values from eachother, take the absolute value, then average them.\n",
    "mae = abs(flat_predictions - flat_true_labels).mean()\n",
    "\n",
    "print('MAE: %.2f' % mae)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0gOJzrPikYe",
    "outputId": "24f39741-603d-4dbd-ebad-597817471aed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 380.70\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second metric is the Root Mean Squared Error (RMSE). The RMSE more heavily punishes large errors because it squares the differences before averaging."
   ],
   "metadata": {
    "id": "rPCpufRDd0-z",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "# First, calculate the squared error for each individual prediction.\n",
    "squared_diffs = (flat_predictions - flat_true_labels)**2\n",
    "\n",
    "# Next, average these error values to get the MSE.\n",
    "mse = squared_diffs.mean()\n",
    "\n",
    "# Finally, take the square root to get the RMSE.\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print('RMSE: %.2f' % rmse)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xb_eAxlhip4T",
    "outputId": "7b28204e-9c22-40ce-92ee-2a692e65c1e8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 516.35\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.save_pretrained(\"drive/MyDrive/local-pt-checkpoint\")\n",
    "model.save_pretrained(\"drive/MyDrive/local-pt-checkpoint\")"
   ],
   "metadata": {
    "id": "FDglLlKniqlR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": []
  }
 ]
}